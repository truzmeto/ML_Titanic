---
title: "Titanic Project"
author: "tar159"
date: "December 15, 2017"
output:
    html_document:
        code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
options(warn = -1)
```

## Introduction

We must regularly go to gym in order to stay fit. Same concept applies to brain muscules towards 
some specific knowledge. One must be active in kaggle to train his/her machine learning muscules.
Anyways, I've decided to do some deeper machine learning after taking some advanced ML courses. Looks
like titanic data set is the best and most popular data to start with. Here, I will exploit some machine learning methods such as "knn", "Dtree", "prunnedTree", "gboosting", "nnet", "SVM" and "rf" with repeated cross validation that helps to choose best hyperparameter for an optimum prediction. Then, I combine 
all predictions of test set to do majority vote. My finale prediction put me at top 9%, which is not bad
for starters, but it is possible to push it even more up by combining more models. 


```{r, echo=TRUE, message=FALSE, warning=FALSE}
## importing libraries
library("knitr")
library("ggplot2")
library("lattice") 
library("caret")
library("rpart")
library("rpart.plot")
library("RColorBrewer")
library("rattle")
library("randomForest")
library("lattice")
library("plyr")
library("Rmisc")
library("party")
library("doMC")
library("corrplot")
library("dplyr")
library("tidyr")
library("rpart.plot")

## loading locally stored data
test_set <- read.csv("../data/test.csv", na.strings = c("NA",""))
train_set <- read.csv("../data/train.csv", na.strings = c("NA",""))

test_set$Survived <- 2
## combining train and test sets
data <- rbind(train_set, test_set)
```


## Preprocessing, Data Cleaning & Feature Extraction

My preprocessing of unclean data is very similar to what most people did. I need to give a credit
to Megan Risdal since I took some chunks from her kernel. 

```{r}
#counting percentage of NA's for each feature
round(colSums(is.na(data))/nrow(data) *100,2)

#Cabin feature have 77.1% missing values, so let's ignore it.
# removing Cabin features from both train and test sets
data$Cabin <- NULL

## creating a new feature by extracting title from names, where we replace
## everything before ', ' and after '.' with '' (empty char.)
data$Titles <- gsub('(.*[,] )|([.].*)', '', data$Name)

## tabulating titles grouped by sex
table(data$Sex, data$Titles)

## taking care of rare female titles
data$Titles[data$Titles == 'Ms'] <- 'Miss' 
data$Titles[data$Titles == 'Mme'] <- 'Mrs' 
data$Titles[data$Titles == 'Mlle'] <- 'Miss' 
data$Titles[data$Titles == 'Dona'] <- 'Miss' 
data[data$Titles == 'Lady',]$Titles <- 'Mrs'
data[data$Titles == 'the Countess',]$Titles <- 'Mrs'
data[data$Sex == 'female' & data$Titles == 'Dr',]$Titles <- 'Miss'

## renaming all rare male titles with most common male title
minor_title_male <- c('Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
data$Titles[data$Titles %in% minor_title_male]  <- 'Mr'

## here we construct values for missing ages by taking
## a mean for each name title. May not be the best way!
mean_age_by_title <- aggregate(Age ~ Titles, data = data, mean)
data[is.na(data$Age) & data$Titles == 'Master' ,]$Age <- mean_age_by_title$Age[1]
data[is.na(data$Age) & data$Titles == 'Miss' ,]$Age <- mean_age_by_title$Age[2]
data[is.na(data$Age) & data$Titles == 'Mr' ,]$Age <- mean_age_by_title$Age[3]
data[is.na(data$Age) & data$Titles == 'Mrs' ,]$Age <- mean_age_by_title$Age[4]

## filling missing fare by mean of passenger class
mean_fare_by_pclass <- aggregate(Fare ~ Pclass, data = data, mean)
data[is.na(data$Fare),]$Fare <- mean_fare_by_pclass$Fare[3]

## imputing missing embarkation type with highest embarkation class
data[is.na(data$Embarked),]$Embarked <- "S"

#kable(table(data$Sex, data$Titles), align = "l")

# age based feature ectraction
data$AdultTeenChi[data$Age <= 12.0] <- "Child"
data$AdultTeenChi[data$Age > 12.0 & data$Age <= 20.0] <- "Teen"
data$AdultTeenChi[data$Age > 20.0 & data$Age <= 35.0] <- "YoungAdult"
data$AdultTeenChi[data$Age > 35.0 & data$Age <= 50.0] <- "MiddleAged"
data$AdultTeenChi[data$Age > 50.0] <- "Siniors"
data$AdultTeenChi <- as.factor(data$AdultTeenChi)
kable(table(data$AdultTeenChi, data$Titles), align = "l")

## recollecting the data back to train and test sets after
## cleaning and imputations are done
data$Titles <- as.factor(data$Titles)
data$Name <- NULL
data$Ticket <- NULL
test_set <- data[data$PassengerId >= 892,]
train_set <- data[data$PassengerId < 892,]
test_set$Survived <- NULL
```

## Exploratory Analysis


```{r, eval=FALSE, echo=FALSE, fig.height=4, fig.width=10, message=FALSE, warning=FALSE}

p1 <- ggplot(train_set, aes(x= Pclass, fill= factor(Survived))) +
            geom_histogram(binwidth=0.4, position="dodge")+
            theme_bw() +
            labs(title = "Survival by passenger class" ,
                    x="Passenger class", color="") +
            theme(axis.title = element_text(size = 16.0),
                    legend.position = c(0.3,0.8),
                    axis.text = element_text(size=12),
                    plot.title = element_text(size = 18, hjust = 0.5),
                    text=element_text(family="Times New Roman")) +
            scale_fill_brewer(palette = "Set1")


p2 <- ggplot(data, aes(x=Fare, fill = Sex)) +
            geom_density(alpha = 1.) +
            theme_bw() +
            labs(title = "Survival by sex" ,
                    x = "Passenger sex",
                     y = "Density", color = "") +
            theme(legend.position = c(0.7,0.8),
                    axis.title = element_text(size = 16.0),
                    axis.text = element_text(size=12),
                    plot.title = element_text(size = 18, hjust = 0.5),
                    text=element_text(family="Times New Roman")) +
            scale_fill_brewer(palette = "Set1")


multiplot(p1,p2,cols=2)
```

## Machine Learning

I used "caret" package with multicore processing to speed up k-fold cross validation. 
It has a lot of ML methods, which can be accesed via following command "names(getModelInfo())".
Training accuracy reported is the accuracy over entire training set. Repeated cross validation
uses repeatedly resampled subsets to validated the model.  

```{r, message=FALSE, warning=FALSE}
## setting seed for random number generator
seed <- 2017
set.seed(seed)
n_cores <- 8
registerDoMC(cores = n_cores)
n_resamples <- n_cores
n_repeats <- 4

## creating a data partition
#train_indx <- createDataPartition(y=train_set$Survived, p = 0.70, list=FALSE)
#Training <- train_set[train_indx, ]
#CrossVal <- train_set[-train_indx, ]
Training <- train_set
```


## K-Nearest Neighbor 

Knn algorithm classifies data points based on K closest neighbors in distance, where
over represented class gets the vote. K value and distance metric are the only
parameters to tune for cross validation. It is slow with large data sets and high dimensional
data. 

```{r knn, eval=TRUE, message=FALSE, warning=FALSE}

list_length <- n_resamples*n_repeats + 1
seeds <- vector(mode = "list", length = list_length)
tuneLength <- 20
for(i in 1:list_length) seeds[[i]] <- sample.int(1000, tuneLength)

knnCtrl <- trainControl(method = "repeatedcv",
                     number = n_resamples,
                     repeats = n_repeats,
                     seeds = seeds,
                     allowParallel = TRUE)

# apply knn to training set
knnFit <- train(factor(Survived) ~ . ,
                    data = Training,
                    method = "knn",
                    metric = "Accuracy",
                    trControl = knnCtrl,
                    preProcess = c("center","scale"),
                    tuneLength = tuneLength)

#plot cross validation curve
plot(knnFit)
```

As depicted in above figure, the best number for neirest neighbour is `r knnFit$bestTune` that gave higest
accuracy. 


## Decision Tree Classification with Post Prunnig 

Here I used decision tree classifier under "rpart" package with maximum information gain to
determine which feature is given a priority for splitting(treeFit). I performed post pruning to prevent
overfitting(PtreeFit), which does in turn score better than original tree(treeFit) on testing set. 


```{r tree, eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
#building a model with trees
treeFit <- rpart(factor(Survived) ~.,
                     data = Training,
                     method = "class",
                     parms = list(split = "information"),
                     #prior = c(.55,.45)),
                     control = rpart.control(minsplit = 5, cp = 0)) 

#plot xerror vs complexity parameter for original tree
plotcp(treeFit)


## plotting tree diagram
rpart.plot(treeFit,
            fallen.leaves = FALSE,
            shadow.col = "gray",
            sub = "Tree Diagram")


## apply prunning using optimum values for "cp" and "nsplit" 
cp <- treeFit$cptable[which.min(treeFit$cptable[,"xerror"]),"CP"]
PtreeFit <- prune(treeFit, cp = cp)

## plotting pruned tree diagram
rpart.plot(PtreeFit,
            fallen.leaves = FALSE,
            cex = 0.2,
            tweak = 2,
            shadow.col = "gray",
            sub = "Pruned Tree Diagram")
```



## Stochastic Gradient Boosting "gbm"

```{r GradBoost, message=FALSE, warning=FALSE}
gbmGrid <-  expand.grid(shrinkage = c(0.1,0.2,0.3,0.4),
                        interaction.depth = c(3,4,5,6), 
                        n.trees = (2:50)*2,
                        n.minobsinnode = 10)

gbmCtrl <- trainControl(method = "repeatedcv",
                           number = n_resamples,
                           repeats = n_repeats,
                           seeds = seeds,
                           allowParallel = TRUE)

gbmFit <- train(factor(Survived) ~ .,
                        data = Training, 
                        method = "gbm", 
                        trControl = gbmCtrl, 
                        verbose = FALSE, 
                        tuneGrid = gbmGrid)

plot(gbmFit)
```


##ML: Random Forest

```{r Random Forest, eval=TRUE, message=FALSE, warning=FALSE}

#Here we create custom rf method repeatedcv method is not implemented with it 
#####################################################################################
customRF <- list(type = "Classification",
                 library = "randomForest",
                 loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"),
                                  class = rep("numeric", 2),
                                  label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
                randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
   predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
#######################################################################################


for(i in 1:list_length) seeds[[i]] <- sample.int(1000, 60) # 4*15=60
tunegrid <- expand.grid(.mtry = c(1:15),
                        .ntree=c(500, 1000, 1500, 2000))
rfCtrl <- trainControl(method = "repeatedcv",
                     number = n_resamples,
                     repeats = n_repeats,
                     seeds = seeds,
                     allowParallel = TRUE)

rfFit <- train(factor(Survived) ~., 
               data = Training,
               method = customRF,
               metric = "Accuracy",
               tuneGrid = tunegrid,
               trControl = rfCtrl)

plot(rfFit)
```


## Neural Network Model

```{r nnet}
for(i in 1:list_length) seeds[[i]] <- sample.int(1000, 64) #n_units*n_decay=8*8=64
nnetCtrl <- trainControl(method = "repeatedcv", 
                           number = n_resamples, 
                           repeats = n_repeats, 
                           classProbs = TRUE, 
                           summaryFunction = twoClassSummary,
                           seeds = seeds,
                           allowParallel = TRUE)

nnetGrid <- expand.grid(size = seq(from = 4, to = 18, by = 2),
                         decay = seq(from = 0.1, to = 0.8, by = 0.1))

nnetFit <- train(make.names(Survived) ~ ., data = Training,
                 method = "nnet",
                 metric = "ROC",
                 trControl = nnetCtrl,
                 preProcess = c("center","scale"),
                 tuneGrid = nnetGrid,
                 verbose = FALSE)

plot(nnetFit)
```

## SVM Radial Kernel

```{r svm_rk}

## Support Vector Machines with radial kernel
SVMctrl <- trainControl(method = "cv", number = n_resamples, verbose = FALSE)

## Fit Radial Kernel----------------------------------------------------------
SVMgridRad <- expand.grid(C = (1:30)*0.1 + 0.2, sigma = c(0.02,0.04,0.06,0.08,0.1))
SVMFit_rk <- train(factor(Survived) ~ .,
                     data = Training, 
                     method = "svmRadial",
                     trControl = SVMctrl,
                     tuneGrid = SVMgridRad,
                     preProc = c("scale","center"),
                     verbose = FALSE)
plot(SVMFit_rk)
```


## SVM Linear Kernel

```{r svm_lk}

## Fit SVM Linear Kernel
SVMgridLin <- expand.grid(C = (1:10)*0.2 + 0.5) 

SVMFit_lk <- train(factor(Survived) ~ .,
                      data = Training, 
                      method = 'svmLinear',
                      trControl = SVMctrl,
                      tuneGrid = SVMgridLin,
                      preProc = c("scale","center"),
                      verbose = FALSE)
```


```{r Predictions, eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}

#predicting cv set
train_pred_boost <- predict(gbmFit, Training, type = "raw")
train_pred_knn <- predict(knnFit, Training, type = "raw")
train_pred_tree <- predict(treeFit, Training, type = "class")
train_pred_Ptree <- predict(PtreeFit, Training, type = "class")
train_pred_rf <- predict(rfFit, Training, type = "raw")
train_pred_nnet <- predict(nnetFit, Training, type = "raw")
train_pred_svmr <- predict(SVMFit_rk, train_set, type="raw")
train_pred_svml <- predict(SVMFit_lk, train_set, type="raw")


#combine all cv predictions into 1 data frame
TrainPredDF <- data.frame("knn" = as.numeric(train_pred_knn) -1,
                       "tree" = as.numeric(train_pred_tree) -1,
                       "Ptree" = as.numeric(train_pred_Ptree) -1,
                       "boost" = as.numeric(train_pred_boost) -1,
                       "rf" = as.numeric(train_pred_rf) -1,
                       "nnet" = as.numeric(train_pred_nnet) -1,
                       "svmR" = as.numeric(train_pred_svmr) -1,
                       "svmL" = as.numeric(train_pred_svml) -1)


#predicting test set
test_pred_boost <- predict(gbmFit, test_set, type = "raw")
test_pred_knn <- predict(knnFit, test_set, type = "raw")
test_pred_tree <- predict(treeFit, test_set, type = "class")
test_pred_Ptree <- predict(PtreeFit, test_set, type = "class")
test_pred_rf <- predict(rfFit, test_set, type = "raw")
test_pred_nnet <- predict(nnetFit, test_set, type = "raw")
test_pred_svmr <- predict(SVMFit_rk, test_set, type="raw")
test_pred_svml <- predict(SVMFit_lk, test_set, type="raw")

TestPredDF <- data.frame("knn" = as.numeric(test_pred_knn) -1,
                         "tree" = as.numeric(test_pred_tree) -1,
                         "Ptree" = as.numeric(test_pred_Ptree) -1,
                         "boost" = as.numeric(test_pred_boost) -1,
                         "rf" = as.numeric(test_pred_rf) -1,
                         "nnet" = as.numeric(test_pred_nnet) -1,
                         "svmR" = as.numeric(test_pred_svmr) -1,
                         "svmL" = as.numeric(test_pred_svml) -1)

```


```{r CorrPlot, message=FALSE, warning=FALSE, fig.width=10, fig.height=5}
#CVPredDF$comb <- as.numeric(cv_pred_comb)
#visualize cv and test predictions via correlation plots
par(mfrow = c(1,2), font = 2, font.main= 10, cex = 0.9)
corrplot.mixed(cor(TestPredDF))
title(main = "Test set", adj = 0.5)
corrplot.mixed(cor(TrainPredDF))
title(main = "Train set", adj = 0.5)
```


```{r combineViaGam, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
TrainPredDF$Survived <- train_set$Survived
train_combFit <- train(factor(Survived) ~. , method = "gam", data = TrainPredDF)
train_pred_comb <- predict(train_combFit, TrainPredDF, type = "raw")
test_pred_comb <- predict(train_combFit, TestPredDF, type = "raw")
```

```{r majority vote, message=FALSE, warning=FALSE}
tmp <- rowSums(TestPredDF) / ncol(TestPredDF)
tmp[tmp >= 0.6] <- 1
tmp[tmp < 0.6] <- 0
test_pred_majority <- tmp
```


```{r, message=FALSE, warning=FALSE,fig.height=5,fig.width=10}
results <- data.frame(knn = c(confusionMatrix(train_pred_knn, Training$Survived)$overall[1],0.78947),
            tree = c(confusionMatrix(train_pred_tree, Training$Survived)$overall[1],0.73205),
            Ptree = c(confusionMatrix(train_pred_Ptree, Training$Survived)$overall[1],0.79425),
            boost = c(confusionMatrix(train_pred_boost, Training$Survived)$overall[1],0.77033),
            rf = c(confusionMatrix(train_pred_rf, Training$Survived)$overall[1],0.78947),
            nnet = c(confusionMatrix(factor(as.numeric(train_pred_nnet)-1), Training$Survived)$overall[1],0.77990),
            svmr = c(confusionMatrix(train_pred_svmr, Training$Survived)$overall[1],0.79904),
            svml = c(confusionMatrix(train_pred_svml, Training$Survived)$overall[1],0.78468),
            row.names = c("train","test"))%>%t()%>%data.frame()
results$method <- rownames(results)

gather(results,train, test, -method, key = "type", value = "scores")%>%
        ggplot(aes(factor(method), scores, fill = type)) + 
            geom_bar(stat="identity", position = "dodge",width = 0.5) + 
            theme_bw() +
            labs(title = "", x = "Method", y = "Scores", color="") +
            scale_fill_brewer(palette = "Set1")

```        


```{r SubmissionPrep, message=FALSE, warning=FALSE,eval=FALSE,echo=FALSE}
## storing and outputing the predicting into csv file
prediction <- test_pred_majority
output <- data.frame(PassengerID = test_set$PassengerId, Survived = prediction)
write.csv(output, file = 'prediction.csv', row.names = F)
```

## Summary




